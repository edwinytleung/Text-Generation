{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation\n",
    "\n",
    "In this notebook we'll use deep learning to generate text in the style of an author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "#download dataset\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char2int = dict((c, i) for i, c in enumerate(chars))\n",
    "int2char = dict((i, c) for i, c in enumerate(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 200285\n"
     ]
    }
   ],
   "source": [
    "# cut the text into semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a sliding window to split the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preface\\n\\n\\nsupposing that truth is a woma',\n",
       " 'face\\n\\n\\nsupposing that truth is a woman--',\n",
       " 'e\\n\\n\\nsupposing that truth is a woman--wha',\n",
       " '\\nsupposing that truth is a woman--what t',\n",
       " 'pposing that truth is a woman--what then',\n",
       " 'sing that truth is a woman--what then? i',\n",
       " 'g that truth is a woman--what then? is t',\n",
       " 'hat truth is a woman--what then? is ther',\n",
       " ' truth is a woman--what then? is there n',\n",
       " 'uth is a woman--what then? is there not ']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n', 'w', 't', 'h', '?', 's', 'h', 'e', 'o', 'g']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets convert the text into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char2int[char]] = 1\n",
    "    y[i, char2int[next_chars[i]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200285, 40, 57)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "Callbacks allow us monitor our model whilst it's training and respond to it, be that by saving weights, inspecting error or calling some custom funciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback, ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first callback well use is one for saving the model when it improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'text-gen.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath,monitor='val_acc',verbose=1,save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second one we'll use is for Tensorboard so we can visulize the training process more easily, this is important because we need to be able to spot overfitting so we know when to stop training the model. After training we can inspect the tensorflow logs by running the bellow to launch the server.\n",
    "\n",
    "```\n",
    "tensorboard --logdir==path/to/log-directory\n",
    "\n",
    "```\n",
    "\n",
    "After you've lanuch visting http://localhost:6006/ to view tensorboard.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='./logs' ,histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally one to print some generated text as the model trains so we can see how stupid the model it is. This part has two steps, first we need to define a sampling function. During training the model will learn a function that given a seqeunce of characters can predict the probality of the next character. However if we always pick the most likely character we end up having a model that always repeats itself. We need to add a degree of randomness to it, this is what the sample function does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second part is to generate the text, we first feed a input sequence into the model. After we get it's prediction we tag that back onto the sequence and feed that sequence back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_text(text):\n",
    "    input_text = to_categorical([ char2int[char] for char in text],len(chars))\n",
    "    return np.expand_dims(input_text,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(text,length=100,temp=0.5):\n",
    "    \n",
    "    \n",
    "    input_text  = onehot_text(text) \n",
    "    \n",
    "    for i in range(length):\n",
    "        \n",
    "        #predict next char\n",
    "        char = int2char[sample(model.predict(input_text)[0],temp)]\n",
    "        #add to text\n",
    "        text += char\n",
    "        #use the next 40 chars for input\n",
    "        input_text = onehot_text(text[-40:])     \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The on epoch end function will get called are each round of traning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch,logs):\n",
    "    \n",
    "    \n",
    "    print(f'--------- Epoch {epoch}----------\\n\\n')\n",
    "    seed_text = np.random.choice(sentences)\n",
    "    \n",
    "    for temp in [0.2,0.5,1,1.2]:\n",
    "        text = generate_text(seed_text,temp=temp)\n",
    "        print(f\"{text}\\n\\n\")\n",
    "    \n",
    "#Have to pass to a lambda callback to use with keras\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "I'm still experimenting with the model architecture, currently the results are still a little non-sensical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,LSTM,Dropout, TimeDistributed, Bidirectional\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#When stacking LSTM we need return_sequences=True\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars)),return_sequences=True ))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Now we're ready to train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "200285/200285 [==============================] - 161s 802us/step - loss: 2.4636\n",
      "--------- Epoch 0----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dom/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:435: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of omission, an additional\n",
      "seduction undersest and the some the prest of the and the som the are and for the and of the some and a the more \n",
      "\n",
      "\n",
      "of omission, an additional\n",
      "seduction undice of the reess of the mens and flom and precurtuous and dect a concest of the the to he wist, in t\n",
      "\n",
      "\n",
      "of omission, an additional\n",
      "seduction undeess of the seal of awents have beakgrend\n",
      "rests wetply this arely evervesmive yen wordh ol the cardi\n",
      "\n",
      "\n",
      "of omission, an additional\n",
      "seduction undeession of when ons\n",
      "gribes,\n",
      "geaine. ralal, do \n",
      "basam kean--will\n",
      "precrests ordlates merepiast to cune\n",
      "\n",
      "\n",
      "Epoch 2/20\n",
      "200285/200285 [==============================] - 155s 772us/step - loss: 1.9429\n",
      "--------- Epoch 1----------\n",
      "ut\n",
      "already it broadens and widens anew, the man and the stand in the conscience and strenger to the more the morality and stance the man and\n",
      "\n",
      "\n",
      "ut\n",
      "already it broadens and widens anew, the time who be the the so it the self and be a stance and perhopers of the conscient the less hid m\n",
      "\n",
      "\n",
      "ut\n",
      "already it broadens and widens anew, s oruiee things,--no incircoinly \"wution may then canyally-spath makned then aring consirnon--of s e\n",
      "\n",
      "\n",
      "ut\n",
      "already it broadens and widens anew, le=queateds coun sadeals ooce, \"realaa upon a poayernon\n",
      "hosen-misthunft and the diforpnnshs-alologio\n",
      "\n",
      "\n",
      "Epoch 3/20\n",
      "200285/200285 [==============================] - 155s 775us/step - loss: 1.8512\n",
      "--------- Epoch 2----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dom/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longer blame, for it is irrational to\n",
      "blers and the man not the self the an an and the self the conscience in a science to the to the sould \n",
      "\n",
      "\n",
      "longer blame, for it is irrational to\n",
      "blecter of man any the appers to that a one and some where delief, is one\n",
      "the are and that which the n\n",
      "\n",
      "\n",
      "longer blame, for it is irrational to\n",
      "bll eoss prongrement to phyare phent is his timm himself\n",
      "for the anttiscary parscular itself estress s\n",
      "\n",
      "\n",
      "longer blame, for it is irrational to\n",
      "blak in at att the narpherence by so ma, desitel maounds is, and one mard., pain as that wimmity brt t\n",
      "\n",
      "\n",
      "Epoch 4/20\n",
      "200285/200285 [==============================] - 152s 761us/step - loss: 1.8206\n",
      "--------- Epoch 3----------\n",
      "personal considerations of advantage is the suster of the some of the self the some of the constion and the some in the man the self so the \n",
      "\n",
      "\n",
      "personal considerations of advantage is and the not moral, the dight of the interte presents of the notnated and siscelys to the force the i\n",
      "\n",
      "\n",
      "personal considerations of advantage is mead. it sunutive marevious depresinely beacing we to even pution,\n",
      "the their ouests, conperition, is\n",
      "\n",
      "\n",
      "personal considerations of advantage is lea ifcarhy; no which is sare preiinuested, ory onigemederned, according resirt may, a glest bach po\n",
      "\n",
      "\n",
      "Epoch 5/20\n",
      "200285/200285 [==============================] - 150s 750us/step - loss: 1.8089\n",
      "--------- Epoch 4----------\n",
      "but such a god does not know\n",
      "what to do the seep and in the perhaps the world and man and the experition of the self and the as the conscien\n",
      "\n",
      "\n",
      "but such a god does not know\n",
      "what to do the of the who even who have reforing to a sees of the passion. the be as the were out it who are so\n",
      "\n",
      "\n",
      "but such a god does not know\n",
      "what to do light, and\n",
      "therepcatiment. that have this are putpreully mustierd of deserding is how new which is r\n",
      "\n",
      "\n",
      "but such a god does not know\n",
      "what to do \"have fuped is thinkly science\n",
      "to cairtal be fituestly\n",
      "they len, an and rataten. thistion s make tra\n",
      "\n",
      "\n",
      "Epoch 6/20\n",
      "200285/200285 [==============================] - 152s 759us/step - loss: 3.0581\n",
      "--------- Epoch 5----------\n",
      " only under the pressure of christian selä äpposeä thäreæt ää ätiää tä ää man äntentääää the strange of the the all the päst and täesää thäs\n",
      "\n",
      "\n",
      " only under the pressure of christian se ésämas oäjerä tämaéé änoäätsä,ää to täctafice oémæst the and thæys and theäapiéiäätentéikeä ofää ét\n",
      "\n",
      "\n",
      " only under the pressure of christian se ämæior tæw, ésyé pëægäwsæäw æ äänessläanly--äakesingsä\"\"wey\n",
      "wlistentural whoémy ovéäpaäææfkäähind f\n",
      "\n",
      "\n",
      " only under the pressure of christian seléyäg traép,\"äihés=ääséwséäi-éaææise yæ may æquencä?\n",
      "\n",
      " in da would tæi metæi from imprat appeanityin\n",
      "\n",
      "\n",
      "Epoch 7/20\n",
      "200285/200285 [==============================] - 153s 762us/step - loss: 13.8870\n",
      "--------- Epoch 6----------\n",
      "-hitherto the altruistic has been\n",
      "lookedäääääääääääääääääääääääääääääääääéäääääääéääääääääääääääääääääääääääääääääääääääääääääääääääääæäääää\n",
      "\n",
      "\n",
      "-hitherto the altruistic has been\n",
      "lookedæääæääæäääéäääéäääääéääéäéæéääääæææääääääääéäæääæääéäëéääëäääääéäääæäéëäääëéääëäéëäæäæääääæäääääæéää\n",
      "\n",
      "\n",
      "-hitherto the altruistic has been\n",
      "lookedääëëæääëääéëäääéäëäääääääéäæäääæäææééäääääääææääëéäæéääééääéæäéééäéäääéäääéääääëääéääéëéëëëäëæääëäëä\n",
      "\n",
      "\n",
      "-hitherto the altruistic has been\n",
      "lookedëéäééæäæäæééëääéääëäääääææëääëëææääææäääëéäääääéäééääééæëëäæëäæëææäæääääéääéäëéäääëëäæéæëééääéäæëäéä\n",
      "\n",
      "\n",
      "Epoch 8/20\n",
      "200285/200285 [==============================] - 153s 763us/step - loss: 16.1180\n",
      "--------- Epoch 7----------\n",
      "he nature of a finer turning or better eéééééëééééééééééééééééééééééééëééééééééëéééééééééééééééééééééééééééééééééééééééééééééééééééééééééééë\n",
      "\n",
      "\n",
      "he nature of a finer turning or better eééééëéééééëééééëéééëéëéëéëëéééëééëëéééééééééééééééëéëééééééééëéééëééëéëéëééëéëéééééééééééééééëéééééé\n",
      "\n",
      "\n",
      "he nature of a finer turning or better eëéëééëéëéééëéëéëééëëééééëééëëëéééëéëéééëéëëëëëëëéëéëééééééééééëëéëééééëééëééééééëéëéééëäééëéëäëééëéé\n",
      "\n",
      "\n",
      "he nature of a finer turning or better eéäëëééäëééäéééëëééëééëëéëéééééæéééëéééëëëëéééééééëéäééééëééëééééëéééëëéëéëëéëëééëéëäééééëäééæëéëëëëä\n",
      "\n",
      "\n",
      "Epoch 9/20\n",
      "200285/200285 [==============================] - 150s 748us/step - loss: 16.1180\n",
      "--------- Epoch 8----------\n",
      "it has competed in it. without such pracééééëééééééëéëééëéééééëééééééééééëéééëééëééééééééééééééééëéééëéééééééëéëééééëééééééééëëééééééééëëééé\n",
      "\n",
      "\n",
      "it has competed in it. without such pracééëéëééééééëëëééééëëéëëëéééééëéëëéëéééëëééëëééëëééëëéëëééééééééééééééëéëéëééëéëéëéëéééëéëéëëééëëëëëé\n",
      "\n",
      "\n",
      "it has competed in it. without such pracëëëëéééééééééëéëéëééëëéëééëééëëëéëëéëëéééëëéëééëëéééééëééëëéééëééééééëëëéééééééëééëééëëééééééëéëëéëë\n",
      "\n",
      "\n",
      "it has competed in it. without such pracëëëäëëééëëééééëééééëëééëéëéëéëëééëééëééëééëééëëëéëéééééëééééëéëëééëëëéééééëéëëéëééééééëëëëëééëëëëéëë\n",
      "\n",
      "\n",
      "Epoch 10/20\n",
      "200285/200285 [==============================] - 159s 792us/step - loss: 16.1180\n",
      "--------- Epoch 9----------\n",
      ", and his will to life had to be\n",
      "increaséééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééé\n",
      "\n",
      "\n",
      ", and his will to life had to be\n",
      "increasééëéééëéééééééééééééééééééëéééééééééééééééééééééééééééééééééëéééééééééééééééééééééééééééëééééééééééé\n",
      "\n",
      "\n",
      ", and his will to life had to be\n",
      "increasééééééééééëééééëëéééééëëéééëéééëééééëéééëééééééééëéëééëééééééëééééééééééééééééééééëéééééëééééëéééééé\n",
      "\n",
      "\n",
      ", and his will to life had to be\n",
      "increaséééééééééééééëééëëééééëééëéëééëééééééëééëééëëéëééëëéééëééééëééëëëéééëéëëéééëééëéëééëëéëéëéëééëéééééë\n",
      "\n",
      "\n",
      "Epoch 11/20\n",
      "200285/200285 [==============================] - 150s 751us/step - loss: 16.1180\n",
      "--------- Epoch 10----------\n",
      "idealistic, feminine, and hermaphroditicééééééééééééééééééééééééééééééééééééééééééééééééëéééééééééééééééééééëééëéééééééééééééééééééééééééééé\n",
      "\n",
      "\n",
      "idealistic, feminine, and hermaphroditicééééééééëéééëééééééééééééééééééëééééééëéééëéééëëéééééééééééééééëéëëééééééééééëéééëéëéëëéëéëéééëëëéëé\n",
      "\n",
      "\n",
      "idealistic, feminine, and hermaphroditicéééëéééééééëéëëëëééééééééééééëëëéééëéééëéééëëéëëëéëééëééëéëëéééëééëééëéééëëééëéëëééééëééëéëëéééééééé\n",
      "\n",
      "\n",
      "idealistic, feminine, and hermaphroditicéééééééëéëéëéééëëéééééëééëééëééééééééééëëééëéééééëëéëééééëëéëéëéëëéëééééëëéëéëéëëéééééééééëëëëéëéëëé\n",
      "\n",
      "\n",
      "Epoch 12/20\n",
      "200285/200285 [==============================] - 150s 751us/step - loss: 16.1180\n",
      "--------- Epoch 11----------\n",
      " and henceforth for ever\n",
      "useless.--in théééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééé\n",
      "\n",
      "\n",
      " and henceforth for ever\n",
      "useless.--in théééééééééééééééééééëéééééëëéééééééééééééééééëéééëééééééééééééééééééééééééééééééééééééééééééééééééééé\n",
      "\n",
      "\n",
      " and henceforth for ever\n",
      "useless.--in théééëéééëééééééééëééééééééëëéëééééééééééëééééééëëééééééééééééééééééééééééëëééééëéëéééëééééëééééééëééé\n",
      "\n",
      "\n",
      " and henceforth for ever\n",
      "useless.--in théééééëééééééëéééééééééééééééëéëéééëëéëééëééééééëéëééëëéééëéééééééëéééééééëëëéééëééééëëëëéëëééëéëéëéé\n",
      "\n",
      "\n",
      "Epoch 13/20\n",
      "200285/200285 [==============================] - 150s 751us/step - loss: 16.1180\n",
      "--------- Epoch 12----------\n",
      "jews: \"the law was for servants;--love géééééééééééééééééëéééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééééé\n",
      "\n",
      "\n",
      "jews: \"the law was for servants;--love gëéééééëéééëéëééëéééééééééëééëéëëëéëééééééééééëéëééééééééééëéééëééééééëééééééëééééééééééééëééééééëëëé\n",
      "\n",
      "\n",
      "jews: \"the law was for servants;--love géëéééééééëéééééééëéééëëëééééééééëëééééëéééééééééëééééééëéëééééëéééëééééëëéëéëéééééëéééëëéëéééééëéééé\n",
      "\n",
      "\n",
      "jews: \"the law was for servants;--love géëééëéééééëéééééééëééééééëëéééééëëëééëëëééëëëéëëëëéëééééééééëéééééëëééëéééééééëëëéééééëééëëéëéééééëé\n",
      "\n",
      "\n",
      "Epoch 14/20\n",
      " 22144/200285 [==>...........................] - ETA: 2:21 - loss: 16.1174"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-afbd29a5a0eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           callbacks=[checkpoint,print_callback,tensorboard])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h = model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          callbacks=[checkpoint,print_callback,tensorboard])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
